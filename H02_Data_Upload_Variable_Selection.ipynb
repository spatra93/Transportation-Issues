{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\programdata\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.externals as extjoblib\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "pd.options.display.max_rows=999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('2020_Competition_Training.csv',low_memory=False)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Categorical Variable (Indicator variable) and Continous Variable (Highly Multicollinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_data=pd.read_csv('drop_columns.csv')\n",
    "dropped_columns=drop_data['names'].tolist()\n",
    "df2=df1.drop(dropped_columns,axis=1)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update Variable DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(df2.dtypes).to_csv('data_type.csv')\n",
    "\n",
    "interval_data=pd.read_csv('Interval_Variables.csv')\n",
    "interval_columns=interval_data['names'].tolist()\n",
    "\n",
    "categorical_data=pd.read_csv('Categorical_Variables.csv')\n",
    "categorical_columns=categorical_data['names'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to Categorical Data (Using Label Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categorical_columns:\n",
    "    df2[i] = df2[i].astype('category')\n",
    "    df2[i] = df2[i].cat.codes\n",
    "    df2[i].fillna(df2[i].mode(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in interval_columns:\n",
    "    df2[i] = (pd.to_numeric(df2[i]))*1.00000\n",
    "    df2[i].fillna(df2[i].mean(),inplace=True)\n",
    "#pd.DataFrame(df2.dtypes).to_csv('data_type_updated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.drop(['transportation_issues','person_id_syn','zip_cd','cnty_cd','state_cd'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=2)\n",
    "gmm.fit(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions from gmm\n",
    "labels = gmm.predict(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For 4 clusters\n",
    "array([[    0,  4192],\n",
    "       [    1, 19981],\n",
    "       [    2, 42457],\n",
    "       [    3,  2942]], dtype=int64)\n",
    "       \n",
    "#For 5 clusters\n",
    "array([[    0, 19586],\n",
    "       [    1,  3000],\n",
    "       [    2, 38343],\n",
    "       [    3,  1798],\n",
    "       [    4,  6845]], dtype=int64)\n",
    "       \n",
    "#For 6 clusters\n",
    "array([[    0,  1423],\n",
    "       [    1,  2098],\n",
    "       [    2, 20661],\n",
    "       [    3,  4958],\n",
    "       [    4, 37689],\n",
    "       [    5,  2743]], dtype=int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform stratified train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Cluster']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['transportation_issues'] = df2['transportation_issues']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_crosstab = pd.crosstab(index=df3['Cluster'], columns=df3['transportation_issues'],margins=True)   # Include row and column totals\n",
    "my_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_Cluster = df3[df3['Cluster']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df3_Cluster.drop(['transportation_issues'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = df3_Cluster[['transportation_issues']]\n",
    "Y['transportation_issues'] = Y['transportation_issues'].astype('category')\n",
    "Y['transportation_issues'] = Y['transportation_issues'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.20, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of Training (X):\",len(X_train))\n",
    "print(\"Length of Training (Y):\",len(y_train))\n",
    "print(\"Length of Test (X):\",len(X_test))\n",
    "print(\"Length of Test (Y):\",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of Y in Overall Data: \",Y['transportation_issues'].value_counts(normalize=True))\n",
    "print(\"Distribution of Y in Train Data: \",y_train['transportation_issues'].value_counts(normalize=True))\n",
    "print(\"Distribution of Y in Test Data: \",y_test['transportation_issues'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Light GBM as a Feature Importance Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.values.astype(np.float32, copy=False)\n",
    "train_data=lgb.Dataset(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Max Depth: 30, AUC Train: 0.8356306010875826, AUC Test:  0.7512941064532952\n",
    "#Max Depth: 25, AUC Train: 0.8356306010875826, AUC Test:  0.7512941064532952\n",
    "#Max Depth: 20, AUC Train: 0.8356306010875826, AUC Test:  0.7512941064532952\n",
    "#Max Depth: 15, AUC Train: 0.8356306010875826, AUC Test:  0.7512941064532952\n",
    "#Max Depth: 12, AUC Train: 0.8347654095204213, AUC Test:  0.7516753138653118\n",
    "#Max Depth: 10, AUC Train: 0.8346912618193673, AUC Test:  0.7519381243918067\n",
    "#Max Depth: 9,  AUC Train: 0.8344044285140264, AUC Test:  0.751128879407961\n",
    "#Max Depth: 8,  AUC Train: 0.8328881168017364, AUC Test:  0.7509371813463662\n",
    "\n",
    "#Max Depth: <=0, AUC Train:  0.932791181302066, AUC Test:  0.7378888286695064,  CV = 5\n",
    "#Max Depth: -1 , AUC Train:  0.8064933442735, AUC Test:  0.7515543566006821,  CV = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default parameters for 1st round training\n",
    "params = {'boosting_type': 'gbdt',\n",
    "         'max_depth' : -1,\n",
    "          'objective': 'binary',\n",
    "          'nthread': 5,\n",
    "          'num_leaves': 64,\n",
    "          'learning_rate': 0.02,\n",
    "          'max_bin': 512,\n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'reg_alpha': 1.2,\n",
    "          'reg_lambda': 1.2,\n",
    "          'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 5,\n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,\n",
    "          'metric' : 'binary_error',\n",
    "          'extra_trees' : 'True',\n",
    "          'is_unbalance' : 'True'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridParams = {\n",
    "    'learning_rate': [0.02,0.03],\n",
    "    'n_estimators': [8,16],\n",
    "    'num_leaves': [20, 24, 27],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [501], \n",
    "    'colsample_bytree' : [0.64, 0.65],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1, 1.2],\n",
    "    'reg_lambda' : [ 1.2, 1.4],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt',\n",
    "       objective = 'binary',\n",
    "          n_jobs = 5, \n",
    "          silent = True,\n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'],\n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'],\n",
    "          subsample_freq = params['subsample_freq'],\n",
    "          min_split_gain = params['min_split_gain'],\n",
    "          min_child_weight = params['min_child_weight'],\n",
    "          min_child_samples = params['min_child_samples'],\n",
    "          scale_pos_weight = params['scale_pos_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid\n",
    "grid = GridSearchCV(mdl, gridParams, verbose=2, cv=8, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the grid\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using parameters already set above, replace in the best from the grid search\n",
    "params['colsample_bytree'] = grid.best_params_['colsample_bytree']\n",
    "params['learning_rate'] = grid.best_params_['learning_rate']\n",
    "#params['num_leaves'] = grid.best_params_['num_leaves']\n",
    "params['reg_alpha'] = grid.best_params_['reg_alpha']\n",
    "params['reg_lambda'] = grid.best_params_['reg_lambda']\n",
    "params['subsample'] = grid.best_params_['subsample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fitting with params: ')\n",
    "print(params)\n",
    "\n",
    "#Train model on selected parameters and number of iterations\n",
    "lgbm = lgb.train(params,\n",
    "                 train_data,\n",
    "                 450,\n",
    "                 #early_stopping_rounds= 40,\n",
    "                 verbose_eval= 4\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on train set\n",
    "predictions_lgbm_prob = lgbm.predict(X_train)\n",
    "predictions_lgbm_01 = np.where(predictions_lgbm_prob > 0.5, 1, 0) #Turn probability to 0-1 binary output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "col_0\t0\t1\tAll\n",
    "transportation_issues\t\t\t\n",
    "0\t47228\t271\t47499\n",
    "1\t6926\t1232\t8158\n",
    "All\t54154\t1503\t55657"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_crosstab = pd.crosstab(index=y_train['transportation_issues'], columns=predictions_lgbm_01,margins=True)   # Include row and column totals\n",
    "my_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot Variable Importances\n",
    "lgb.plot_importance(lgbm, max_num_features=15, importance_type='split')\n",
    "\n",
    "#Print accuracy\n",
    "acc_lgbm = accuracy_score(y_train,predictions_lgbm_01)\n",
    "print('Overall accuracy of Light GBM model:', acc_lgbm)\n",
    "\n",
    "#Print Area Under Curve\n",
    "plt.figure()\n",
    "false_positive_rate, recall, thresholds = roc_curve(y_train, predictions_lgbm_prob)\n",
    "roc_auc = auc(false_positive_rate, recall)\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.plot(false_positive_rate, recall, 'b', label = 'AUC = %0.3f' %roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Fall-out (1-Specificity)')\n",
    "plt.show()\n",
    "\n",
    "print('AUC score:', roc_auc)\n",
    "\n",
    "#Print Confusion Matrix\n",
    "plt.figure()\n",
    "cm = confusion_matrix(y_train, predictions_lgbm_01)\n",
    "labels = ['No Default', 'Default']\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, xticklabels = labels, yticklabels = labels, annot = True, fmt='d', cmap=\"Blues\", vmin = 0.2);\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on train set\n",
    "predictions_lgbm_prob = lgbm.predict(X_test)\n",
    "predictions_lgbm_01 = np.where(predictions_lgbm_prob > 0.5, 1, 0) #Turn probability to 0-1 binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Variable Importances\n",
    "lgb.plot_importance(lgbm, max_num_features=10, importance_type='split')\n",
    "\n",
    "#Print accuracy\n",
    "acc_lgbm = accuracy_score(y_test,predictions_lgbm_01)\n",
    "print('Overall accuracy of Light GBM model:', acc_lgbm)\n",
    "\n",
    "#Print Area Under Curve\n",
    "plt.figure()\n",
    "false_positive_rate, recall, thresholds = roc_curve(y_test, predictions_lgbm_prob)\n",
    "roc_auc = auc(false_positive_rate, recall)\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.plot(false_positive_rate, recall, 'b', label = 'AUC = %0.3f' %roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Fall-out (1-Specificity)')\n",
    "plt.show()\n",
    "\n",
    "print('AUC score:', roc_auc)\n",
    "\n",
    "#Print Confusion Matrix\n",
    "plt.figure()\n",
    "cm = confusion_matrix(y_test, predictions_lgbm_01)\n",
    "labels = ['No Default', 'Default']\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, xticklabels = labels, yticklabels = labels, annot = True, fmt='d', cmap=\"Blues\", vmin = 0.2);\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test\n",
    "X_train_trim = X_train[['est_age']]\n",
    "X_test_trim = X_test[['est_age']]\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0) \n",
    "classifier.fit(X_train_trim, y_train) \n",
    "\n",
    "y_pred = classifier.predict(X_train_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(\"Confusion Matrix : \\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Accuracy : \", accuracy_score(y_train, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test_trim)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix : \\n\", cm)\n",
    "print (\"Accuracy : \", accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Area Under Curve\n",
    "plt.figure()\n",
    "false_positive_rate, recall, thresholds = roc_curve(y_test,y_pred)\n",
    "roc_auc = auc(false_positive_rate, recall)\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.plot(false_positive_rate, recall, 'b', label = 'AUC = %0.3f' %roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Fall-out (1-Specificity)')\n",
    "plt.show()\n",
    "\n",
    "print('AUC score:', roc_auc)\n",
    "\n",
    "#Print Confusion Matrix\n",
    "plt.figure()\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labels = ['No Default', 'Default']\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, xticklabels = labels, yticklabels = labels, annot = True, fmt='d', cmap=\"Blues\", vmin = 0.2);\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
